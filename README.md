# BellaBeat-CaseStudy

## Project Summary

The following repository is my analysis done in SQL and R for the Bellabeat Case Study as a part of the Google Data Analytics Capstone Project. The following steps showcase my thought process during the Ask, Prepare, Process and Analyze phases, visualizations created from the previously mentioned steps, and include my conclusions and recommendations for the business task presented. 


In our case study we are working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. We are asked by Urška Sršen, founder of Bellabeat, to analyze smart device usage data in order to gain      insight into how consumers use non-Bellabeat smart devices.

**Business Task:** Identify trends, patterns, and key information from data generated by non-Bellabeat smart devices and apply these insights to an already existing Bellabeat product.

### Data Sources   

- FitBit Fitness Tacker Data [(Download Here)](https://www.kaggle.com/datasets/arashnic/fitbit)

## Ask Phase

To attempt to solve the business task I came up with the following questions: 
1. What is the impact of recommended moderate and high intensity activity on calories burned?
2. What is the impact of recommended steps on calories burned?
3. Does the total amount of active minutes affect the percentage of time asleep while in bed?


## Prepare Phase 

### Data Sources

For our analysis we will be using the [Fitbit Fitness Tracker Data](https://www.kaggle.com/datasets/arashnic/fitbit).
> 18 CSV files
> 
> License: CC0: Public Domain

### Bias and Credibility

The Fitbit Fitness Tracker Dataset is second party data collected by Amazon Mechanical Turk using a Fitbit smart device. The data is quantitative, structured, relational, both long and wide, and stored in CSV format. Due to this being second party data, we do not the know the participants who were selected or why this data was collected in the first place. 

### Limitations

The Fitbit Fitness Tracker Dataset Limitations include: 

- Small sample size (15-34)
- Gender not confirmed
- Older data


## Process Phase 

### Selecting Data  

We begin the process phase by selecting which data files to use. For our analysis we will be focusing on the following csv. files:

- [dailyActvity_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/dailyActivity_merged.csv)  
- [dailyCalories_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/dailyCalories_merged.csv)
- [dailySteps_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/dailySteps_merged.csv)
- [sleepDay_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/sleepDay_merged.csv)

### Data Importing 

I began by attempting to import the CSV files into [BigQuery](https://cloud.google.com/bigquery?hl=en). The sleepDay_merged.csv needed the date and time column to be converted to the correct datetime data type format in order to be imported into bigquery. To do this the following steps were taken in Microsoft Excel:
1. Click and highlight column B containing to the date and time in its orginal format
2. Select Format menu option
3. Cell option
4. Under the Number tab select Date and click the correct datetime format YYYY-MM-DD HH:MI:SS that is accepted by BigQuery

### Data Cleaning 

Once our data has been imported, we want to clean our data and ensure its integrity before our analysis step. We start exploring the [dailyActivity_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/dailyActivity_merged.csv) dataset and the values we are interested in. 

```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: daily_activity 

SELECT 
  COUNT(DISTINCT(ID)) as num_of_participants,
  MIN(ActivityDate) as start_date,
  MAX(ActivityDate) as end_date,
  MIN(TotalSteps) as min_total_steps,
  MAX(TotalSteps) as max_total_steps,
  MIN(Calories) as min_calories,
  MAX(Calories) as max_calories,
  MIN(SedentaryMinutes) as min_sed_minu,
  MAX(SedentaryMinutes) as max_sed_minu
FROM 
  `black-heading-417023.FitBit_Data.daily_activity`
```

```sql
Results: 

  "num_of_participants": "33",
  "start_date": "2016-04-12",
  "end_date": "2016-05-12",
  "min_total_steps": "0",
  "max_total_steps": "36019",
  "min_calories": "0",
  "max_calories": "4900",
  "min_sed_minu": "0",
  "max_sed_minu": "1440"

```


From this query we notice that there are values of 0 for TotalSteps, Calories, and SedentaryMinutes. To avoid any skewed results we delete any rows that have 0 as a value with the following query: 


```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: daily_activity

DELETE FROM
`black-heading-417023.FitBit_Data.daily_activity` 
WHERE
  TotalSteps = 0 OR
  SedentaryMinutes = 0 OR
  Calories = 0  

-- table is then saved as daily_activity 
```

Our [dailyCalories_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/dailyCalories_merged.csv) dataset searched for any error entries where Calories = 0, these rows were then deleted.

```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: daily_calories

SELECT *
FROM 
  `black-heading-417023.FitBit_Data.daily_calories` 
WHERE
  Calories = 0

Results:

  "Id": "1503960366",
  "ActivityDay": "2016-05-12",
  "Calories": "0"
}, {
  "Id": "6290855005",
  "ActivityDay": "2016-05-10",
  "Calories": "0"
}, {
  "Id": "8583815059",
  "ActivityDay": "2016-05-12",
  "Calories": "0"
}, {
  "Id": "8253242879",
  "ActivityDay": "2016-04-30",
  "Calories": "0"
```
 

```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: daily_calories

-- rows where calories = 0 are then deleted

DELETE FROM 
  `black-heading-417023.FitBit_Data.daily_calories` 
WHERE
  Calories = 0

-- table is then saved as daily_calories
```


For the [dailySteps_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/dailySteps_merged.csv) data we will be searching for and eliminating any rows where the value of TotalSteps = 0.

```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: daily_steps

-- searching for entries where TotalSteps = 0

SELECT COUNT(*) as error_entries
FROM 
`black-heading-417023.FitBit_Data.daily_steps`
WHERE
  StepTotal = 0
```

```sql
Results:

[{
  "error_entries": "77"
}]
```

```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: daily_steps

-- Deleting entries where TotalSteps = 0

DELETE FROM 
`black-heading-417023.FitBit_Data.daily_steps`
WHERE
  StepTotal = 0

-- table then saved as daily_steps
```

For our [sleepDay_merged.csv](https://github.com/jose-argu/BellaBeat-CaseStudy/blob/56c59ce4b6a1b3954185c6d343581788b0859014/sleepDay_merged.csv) dataset we will want to: 
1. Confirm there are no values = 0 in the TotalMinutesAsleep or TotalTimeInBed columns.
2. Transform the SleepDay column data type from TIMESTAMP to DATE in order to be able to JOIN these tables in our analysis. 

```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: sleep_day

-- Checking for values = 0 in TotalMinutesAsleep or TotalTimeInBed columns

SELECT * 
FROM 
  `black-heading-417023.FitBit_Data.sleep_day` 
WHERE
  TotalMinutesAsleep = 0 OR
  TotalTimeInBed = 0

Results:
No rows are returned from the query above.

```


```sql
-- projectname: black-heading-417023
-- datasetname: FitBit_Data
-- tablename: sleep_day

-- Changing SleepDay data type from TIMESTAMP to DATE
SELECT 
  Id,
  CAST(SleepDay as DATE) as SleepDate,
  TotalSleepRecords,
  TotalMinutesAsleep,
  TotalTimeInBed
FROM 
  `black-heading-417023.FitBit_Data.sleep_day` 

  -- table then saved as sleep_day_cleaned

```
